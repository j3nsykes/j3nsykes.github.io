<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>Creative ML @JenSykes</title>
  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:200,200i,300,300i,400,400i,500,500i,600,600i,700,700i&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="main.css">
</head>

<body>
  <div id="wrapper">

    <h1>Creative ML</h1>
    <h3>with JenSykes</h3>
    <section>
      <h1>Intro</h1>
      <p>This page provides the resources as part of the GSA IxD Sense and Sensibility project. This project explores the realm of computer consciousness, including exploring computer vision, artificial intelligence (AI), machine learning (ML); their
        associated toolsets, philosophical and ethical considerations.</p>
      <p>You are expected to build upon the examples provided and take them in personal directions going beyond their 'out of the box' nature. </p>
      <p><a href="">Source Code for all examples</a></p>
      <p><a href="https://drive.google.com/open?id=19UTk6T8J4IlIImGOYtHYpPmcde0JymJo" target="_blank">Guide to Tools</a></p>
    <br>
      <h2>Examples of other people's work</h2>
      <p><a href="https://andreasrefsgaard.dk/project/eye-conductor/" target="_blank">Eye Conductor by Andreas Refsgaard</a></p>
      <p><a href="http://bjoernkarmann.dk/project_alias  http://bjoernkarmann.dk/objectifier" target="_blank">Objectifier by Bjorn Karmann</a></p>
      <p><a href="http://ciid.dk/education/portfolio/idp17/courses/machine-learning/projects/kolam/" target="_blank">Kolam by CIID</a></p>
      <p><a href="https://jk-lee.com/geography-of-hidden-faces" target="_blank">Hidden Faces by Joey Lee</a></p>
    </section>

    ---------------------------------------------------------------------------->
    <section>
      <h1>Part 1: Classification and Regression</h1>
      <h2>Teachable Machines</h2>
      <p>We will explore classification using Google's Teachable Machine resource.</p>
      <p>Remember to sign in then duplicate any P5JS examples in order to edit and save your changes. </p>
      <ul><a href="https://teachablemachine.withgoogle.com/" target="_blank">Google's Teachable Machine</a></ul>
      <ul><a href="https://editor.p5js.org/jen_GSA/sketches/nC93Bd3W" target="_blank">Teachable Machine Template</a></ul>
      <ul><a href="https://editor.p5js.org/jen_GSA/sketches/1HovDB5X" target="_blank">Image Classifier</a></ul>
      <ul><a href="https://editor.p5js.org/jen_GSA/sketches/a3CYSsKd" target="_blank">Sound Classifier</a></ul>

      <!--
      <ul><a href="" target="_blank">Example 4</a></ul>
      <ul><a href="" target="_blank">Example 5</a></ul>
-->
      ---------------------------------------------------------------------------->

      <h3>Exercise 1</h3>
      <p>Try make a change to an output in your Teachable Machine template.
        Look for the key variables to identify your classification label.
        Perhaps change a shape,text, image or sound as an output. </p>

      <p><strong>Extra Resources:</strong>
      </p>

      <ul>
        <p>Sometimes its quicker to use the <a href="https://editor.p5js.org/jen_GSA/sketches/6h4uZIje" target="_blank">ML5 webcam classifier</a> than always jumping on the back of Google's Teachable Machine.
        </p>
      </ul>
      <ul><a href="" target="_blank">Advice on advancing your webcam training methods</a></ul>
      ---------------------------------------------------------------------------->
  </section>
  <section>
      <h2>Classiification</h2>
      <p>Lets explore what is happening behind the scenes of the Teachable Machine examples.</p>
      <ul>
        <a href="https://editor.p5js.org/jen_GSA/sketches/fdTIbwlv-" target="_blank">Simple mouse XY classification</a>
        <p>Using your mouse explore how to train a neural net using classification.</p>
      </ul>

      <ul>
        <a href="https://editor.p5js.org/Charlotte000/full/T5amlpxoF" target="_blank">Colourful visual of KNN nearest neighbour</a>
        <p>A really nice example by <a href="https://github.com/Charlotte000" target="_blank">Charlotte 000</a></p>
      </ul>
    </section>
      ---------------------------------------------------------------------------->
  <section>
      <h2>Regression</h2>
      <p>We might not always want distinct label outputs. What if we want a more continuous output or prediction? This is where <strong>regression</strong> comes in. </p>
      <ul>
        <a href="https://editor.p5js.org/jen_GSA/sketches/m4Vjf5UI" target="_blank">Regression basics.</a>
        <p>Using your mouse explore how to train using regression.</p>
      </ul>

      <ul>
        <a href="https://editor.p5js.org/jen_GSA/sketches/RKesj9aS" target="_blank">Webcam Regression</a>
        <p>Use your webcam to train using regression</p>
      </ul>

      <h3>Exercise 2</h3>
      <ul>
        <p>Try changing a different output with regression</p>
        <a href="" target="_blank">Typography</a>
      </ul>
      <ul>
        <a href="https://editor.p5js.org/AndreasRef/sketches/HyEDToYnQ" target="_blank">Playback rate (by Andreas Refsgaard)</a>

      </ul>
  </section>

      ---------------------------------------------------------------------------->
  <section>
      <h2>Pre-trained Models</h2>
      <p>Many ML models we may have encountered in RunwayML utilise pre-trained models. These models already have dataset labels or keypoints we can reference in training.</p>
      <ul>
        <a href="https://editor.p5js.org/jen_GSA/sketches/k_kPeeXd0" target="_blank">MobileNet</a>
        <p>MobileNet uses pretrained labels found in the <a href=" http://image-net.org/papers/imagenet_cvpr09.pdf" target="_blank">ImageNet dataset.</a></p>
      </ul>
      <ul>
        <a href="https://editor.p5js.org/jen_GSA/sketches/fpNvF4wFm" target="_blank">YOLO</a>
        <p>YOLO is similar to MobileNet but uses slightly different methods with its pre-trained model<a href="https://pjreddie.com/darknet/yolo/" target="_blank"> more information here</a></p>
      </ul>
      <ul>
        <a href="https://editor.p5js.org/jen_GSA/sketches/hvA83tad" target="_blank">PoseNet</a>
        <p>Classify poses using the ML5 PoseNet model</p>
      </ul>
      <ul>
        <a href="https://editor.p5js.org/jen_GSA/sketches/xQkDSI60" target="_blank">Face API</a>
        <p>Using ML5 Face API we can track facial expressions and use them as inputs for training.</p>
      </ul>

      <h3>Exercise 2</h3>
      <p>Try train a classification output with the Face API example</p>
      <ul>
        <a href="https://editor.p5js.org/jen_GSA/sketches/JMWnIGsn" target="_blank">Example</a>
      </ul>

      ---------------------------------------------------------------------------->
    </section>


    <section>
      <!--
          commented out notes
-->

      <h1>Part 2 : DIY Neural Nets, physical inputs and Runway ML</h1>
      <h2>DIY neural Nets</h2>
      ---------------------------------------------------------------------------->

      <h2>Physical Inputs</h2>

      <h3>Accellerometers</h3>
      <h3>Capacitive Touch</h3>

      <!--                <ul><img src=""></ul>
                <ul><a href="" target="_blank">Simple template:</a></ul>
                <ul><a href="" target="_blank">List 1</a></ul>
                <ul><a href="h" target="_blank">List 2</a></ul>

-->
      ---------------------------------------------------------------------------->

      <h2>Runway ML</h2>
      <p>We will explore going beyond the Runway ML interface. How we can communicate in and out of it using P5JS, Arduino and Processing
      </p>

      <br>

      ---------------------------------------------------------------------------->
      <h2>External Links</h2>
      <ul><a href="https://ml5js.org/reference/">Documentation + more examples on ml5js.org</a></ul>
      <ul><a href="https://p5js.org/reference/" target="_blank">Official p5.js reference</a></ul>
      <ul><a href="https://runwayml.com/" target="_blank">RunwayML</a></ul>
      <ul><a href="https://github.com/runwayml/processing-library" target="_blank">Processing Library for RunwayML</a></ul>
    </section>


    <section>

      <h2>J3n Sykes</h2>
      <!--  <p><a href="https://twitter.com/J3nSykes">Twitter</a> | <a href="https://github.com/j3nsykes">GitHub</a></p>
-->
      <a href="https://github.com/j3nsykes">GitHub</a></p>
    </section>

  </div>

</body>

</html>
